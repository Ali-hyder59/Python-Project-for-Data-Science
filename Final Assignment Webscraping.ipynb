{"cells":[{"cell_type":"markdown","metadata":{},"source":["<h1>Extracting Stock Data Using a Web Scraping</h1>\n"]},{"cell_type":"markdown","metadata":{},"source":["Not all stock data is available via API in this assignment; you will use web-scraping to obtain financial data. You will be quizzed on your results.  \n"," Using beautiful soup we will extract historical share data from a web-page.\n"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Table of Contents</h2>\n","<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n","    <ul>\n","        <li>Downloading the Webpage Using Requests Library</li>\n","        <li>Parsing Webpage HTML Using BeautifulSoup</li>\n","        <li>Extracting Data and Building DataFrame</li>\n","    </ul>\n","<p>\n","    Estimated Time Needed: <strong>30 min</strong></p>\n","</div>\n","\n","<hr>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["#!pip install pandas==1.3.3\n","#!pip install requests==2.26.0\n","!mamba install bs4==4.10.0 -y\n","!mamba install html5lib==1.1 -y\n","!pip install lxml==4.6.4\n","#!pip install plotly==5.3.1"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["import pandas as pd\n","import requests\n","from bs4 import BeautifulSoup"]},{"cell_type":"markdown","metadata":{},"source":["## Using Webscraping to Extract Stock Data Example\n"]},{"cell_type":"markdown","metadata":{},"source":["First we must use the `request` library to downlaod the webpage, and extract the text. We will extract Netflix stock data [https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/netflix_data_webpage.html](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/netflix_data_webpage.html).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/netflix_data_webpage.html\"\n","\n","data  = requests.get(url).text"]},{"cell_type":"markdown","metadata":{},"source":["Next we must parse the text into html using `beautiful_soup`\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["soup = BeautifulSoup(data, 'html5lib')"]},{"cell_type":"markdown","metadata":{},"source":["Now we can turn the html table into a pandas dataframe\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["netflix_data = pd.DataFrame(columns=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"])\n","\n","# First we isolate the body of the table which contains all the information\n","# Then we loop through each row and find all the column values for each row\n","for row in soup.find(\"tbody\").find_all('tr'):\n","    col = row.find_all(\"td\")\n","    date = col[0].text\n","    Open = col[1].text\n","    high = col[2].text\n","    low = col[3].text\n","    close = col[4].text\n","    adj_close = col[5].text\n","    volume = col[6].text\n","    \n","    # Finally we append the data of each row to the table\n","    netflix_data = netflix_data.append({\"Date\":date, \"Open\":Open, \"High\":high, \"Low\":low, \"Close\":close, \"Adj Close\":adj_close, \"Volume\":volume}, ignore_index=True)    "]},{"cell_type":"markdown","metadata":{},"source":["We can now print out the dataframe\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["netflix_data.head()"]},{"cell_type":"markdown","metadata":{},"source":["We can also use the pandas `read_html` function using the url\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["read_html_pandas_data = pd.read_html(url)"]},{"cell_type":"markdown","metadata":{},"source":["Or we can convert the BeautifulSoup object to a string\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["read_html_pandas_data = pd.read_html(str(soup))"]},{"cell_type":"markdown","metadata":{},"source":["Beacause there is only one table on the page, we just take the first table in the list returned\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["netflix_dataframe = read_html_pandas_data[0]\n","\n","netflix_dataframe.head()"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}
